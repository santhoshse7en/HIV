{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIV News articles extraction from Daily Outlook Afghanistan. Data Extraction of following parameters\n",
    "- Headline\n",
    "- Description\n",
    "- Author\n",
    "- Published Date\n",
    "- Category\n",
    "- Publication\n",
    "- News\n",
    "- URL\n",
    "- Keywords\n",
    "- Summary\n",
    "\n",
    "### Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options # enables options in web browser\n",
    "from selenium import webdriver # web-based automation tool for Python\n",
    "from newspaper import Article # Article scraping & curation\n",
    "from bs4 import BeautifulSoup # Python library for pulling data out of HTML and XML files\n",
    "from requests import get # standard for making HTTP requests in Python\n",
    "import pandas as pd # library written for data manipulation and analysis\n",
    "import sys, time #  System-specific parameters and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Empty lists for HIV News Articles parameters data to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines, descriptions, dates, authors, news, keywords, summaries, urls, category, publication = [], [], [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the total no.of.pages by total no.of articles from google search resultsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'HIV site:outlookafghanistan.net'\n",
    "\n",
    "url = 'https://www.google.com/search?q=' + '+'.join(keyword.split())\n",
    "\n",
    "soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "try:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 680 results (0.23 seconds)\n",
    "    max_pages = round([int(s) for s in soup.select_one('div#resultStats').text.split() if s.isdigit()][0]/10)\n",
    "    max_pages = max_pages + 1\n",
    "except:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 1,080 results (0.23 seconds)\n",
    "    max_pages = round(int(''.join(i for i in soup.select_one('div#resultStats').text if i.isdigit()))/10)\n",
    "    max_pages = max_pages + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates max_pages value through while loop. Scraping the Articles urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 : 21\r"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome(options=options)\n",
    "browser.get(url)\n",
    "\n",
    "index = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        index +=1\n",
    "        page = browser.page_source\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        linky = [soup.select('.r')[i].a['href'] for i in range(len(soup.select('.r')))]\n",
    "        urls.extend(linky)\n",
    "        if index == max_pages:\n",
    "            break\n",
    "        browser.find_element_by_xpath('//*[@id=\"pnnext\"]/span[2]').click()\n",
    "        time.sleep(2)\n",
    "        sys.stdout.write('\\r' + str(index) + ' : ' + str(max_pages) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To remove duplicates urls entries in the list by executing below line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Extracted URL's are : 87 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "urls = list(dict.fromkeys(urls))\n",
    "print(\"Total Extracted URL's are\" + ' : ' + str(len(urls)), type(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates urls through for loop. Scraping the Articles with above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 : http://outlookafghanistan.net/national.php?pageNum_national=280&totalRows_national=9884.pdfional=2346\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GM\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 431 bytes but only got 3. Skipping tag 33432\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "C:\\Users\\GM\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 53safghanistan.net/assets/epaper/June%2007,%202017/See%20Back%20Page.pdf56pdf\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, url in enumerate(urls):\n",
    "    try:\n",
    "        # Parse the url to NewsPlease \n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        \n",
    "        # Extracts the Headlines\n",
    "        try:\n",
    "            headlines.append(article.title.strip())\n",
    "        except:\n",
    "            headlines.append(None)\n",
    "            \n",
    "        # Extracts the Descriptions    \n",
    "        try:\n",
    "            descriptions.append(article.meta_description.strip())\n",
    "        except:\n",
    "            descriptions.append(None)\n",
    "            \n",
    "        # Extracts the Authors\n",
    "        try:\n",
    "            authors.append(article.authors.strip())\n",
    "        except:\n",
    "            authors.append(None)\n",
    "        \n",
    "        # Extracts the published dates\n",
    "        try:\n",
    "            dates.append(article.meta_data['article']['published_time'].split('T')[0])\n",
    "        except:\n",
    "            dates.append(None)\n",
    "            \n",
    "        # Extracts the news category\n",
    "        try:\n",
    "            category.append(article.meta_data['category'])\n",
    "        except:\n",
    "            category.append(None)\n",
    "            \n",
    "        # Extracts the news articles\n",
    "        try:\n",
    "            news.append(' '.join(article.text.split()).replace(\"\\'\\'\",\" \").replace(\"\\'\", \"\").replace(\" / \", \"\"))\n",
    "        except:\n",
    "            news.append(None)\n",
    "            \n",
    "        # Extracts the news publication\n",
    "        try:\n",
    "            publication.append(article.meta_data['og']['site_name'])\n",
    "        except:\n",
    "            publication.append(None)\n",
    "\n",
    "        # Extracts Keywords and Summaries\n",
    "        try:\n",
    "            keywords.append(article.keywords)\n",
    "            summaries.append(' '.join(article.summary.split()))\n",
    "        except:\n",
    "            keywords.append(None)\n",
    "            summaries.append(None)\n",
    "                        \n",
    "    except:\n",
    "        headlines.append(None)\n",
    "        descriptions.append(None)\n",
    "        authors.append(None)\n",
    "        dates.append(None)\n",
    "        category.append(None)\n",
    "        publication.append(None)\n",
    "        news.append(None)\n",
    "        keywords.append(None)\n",
    "        summaries.append(None)\n",
    "\n",
    "    sys.stdout.write('\\r' + str(index) + ' : ' + str(url) + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Array Length of each list to create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 87 87 87 87 87 87 87 87 87\n"
     ]
    }
   ],
   "source": [
    "print(len(headlines), len(descriptions), len(authors), len(dates), len(category), len(publication), len(news), len(keywords), len(summaries), len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a csv file after checking array length and droping the missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_Dates</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Articles</th>\n",
       "      <th>category</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Summaries</th>\n",
       "      <th>Source_URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where are the Nurses in the HIV Response?</td>\n",
       "      <td>Opinion: Since the beginning of the HIV epidem...</td>\n",
       "      <td>None</td>\n",
       "      <td>August 01, 2018</td>\n",
       "      <td>Daily Outlook Afghanistan, the Leading Indepen...</td>\n",
       "      <td>Since the beginning of the HIV epidemic, nurse...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[nurses, nursing, epidemic, support, response,...</td>\n",
       "      <td>Since the beginning of the HIV epidemic, nurse...</td>\n",
       "      <td>http://www.outlookafghanistan.net/topics.php?p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dramatic Increase in HIV/Aids</td>\n",
       "      <td>Opinion: Afghanistan is in the early stage of ...</td>\n",
       "      <td>None</td>\n",
       "      <td>December 06, 2016</td>\n",
       "      <td>Daily Outlook Afghanistan, the Leading Indepen...</td>\n",
       "      <td>Afghanistan is in the early stage of dramatic ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[million, dramatic, status, increase, report, ...</td>\n",
       "      <td>Afghanistan is in the early stage of dramatic ...</td>\n",
       "      <td>http://outlookafghanistan.net/topics.php?post_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HIV/AIDS Epidemic in Afghanistan</td>\n",
       "      <td>Opinion: The Ministry of Health has reported t...</td>\n",
       "      <td>None</td>\n",
       "      <td>December  04, 2012</td>\n",
       "      <td>Daily Outlook Afghanistan, the Leading Indepen...</td>\n",
       "      <td>The Ministry of Health has reported that there...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[epidemic, infected, aids, awareness, drug, he...</td>\n",
       "      <td>Afghanistan is increasingly facing an HIV epid...</td>\n",
       "      <td>http://outlookafghanistan.net/topics.php?post_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HIV is Also a Tragedy</td>\n",
       "      <td>Opinion: Sunday, December 1st, was World AIDS ...</td>\n",
       "      <td>None</td>\n",
       "      <td>December 04, 2013</td>\n",
       "      <td>Daily Outlook Afghanistan, the Leading Indepen...</td>\n",
       "      <td>Sunday, December 1st, was World AIDS Day which...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[infected, cultivation, rise, drug, tragedy, c...</td>\n",
       "      <td>According to BBC reports, Mohammad Ali, who is...</td>\n",
       "      <td>http://outlookafghanistan.net/topics.php?post_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan's HIV Rate Up 38 Percent in 2013</td>\n",
       "      <td>News: KABUL - Officials of the Ministry of Pub...</td>\n",
       "      <td>None</td>\n",
       "      <td>December 02, 2013</td>\n",
       "      <td>Daily Outlook Afghanistan, the Leading Indepen...</td>\n",
       "      <td>KABUL - Officials of the Ministry of Public He...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[unicef, rate, 38, children, afghanistans, hea...</td>\n",
       "      <td>KABUL - Officials of the Ministry of Public He...</td>\n",
       "      <td>http://outlookafghanistan.net/national_detail....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Headlines  \\\n",
       "0     Where are the Nurses in the HIV Response?   \n",
       "1                 Dramatic Increase in HIV/Aids   \n",
       "2              HIV/AIDS Epidemic in Afghanistan   \n",
       "3                         HIV is Also a Tragedy   \n",
       "4  Afghanistan's HIV Rate Up 38 Percent in 2013   \n",
       "\n",
       "                                        Descriptions Authors  \\\n",
       "0  Opinion: Since the beginning of the HIV epidem...    None   \n",
       "1  Opinion: Afghanistan is in the early stage of ...    None   \n",
       "2  Opinion: The Ministry of Health has reported t...    None   \n",
       "3  Opinion: Sunday, December 1st, was World AIDS ...    None   \n",
       "4  News: KABUL - Officials of the Ministry of Pub...    None   \n",
       "\n",
       "      Published_Dates                                        Publication  \\\n",
       "0     August 01, 2018  Daily Outlook Afghanistan, the Leading Indepen...   \n",
       "1   December 06, 2016  Daily Outlook Afghanistan, the Leading Indepen...   \n",
       "2  December  04, 2012  Daily Outlook Afghanistan, the Leading Indepen...   \n",
       "3   December 04, 2013  Daily Outlook Afghanistan, the Leading Indepen...   \n",
       "4   December 02, 2013  Daily Outlook Afghanistan, the Leading Indepen...   \n",
       "\n",
       "                                            Articles category  \\\n",
       "0  Since the beginning of the HIV epidemic, nurse...       {}   \n",
       "1  Afghanistan is in the early stage of dramatic ...       {}   \n",
       "2  The Ministry of Health has reported that there...       {}   \n",
       "3  Sunday, December 1st, was World AIDS Day which...       {}   \n",
       "4  KABUL - Officials of the Ministry of Public He...       {}   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [nurses, nursing, epidemic, support, response,...   \n",
       "1  [million, dramatic, status, increase, report, ...   \n",
       "2  [epidemic, infected, aids, awareness, drug, he...   \n",
       "3  [infected, cultivation, rise, drug, tragedy, c...   \n",
       "4  [unicef, rate, 38, children, afghanistans, hea...   \n",
       "\n",
       "                                           Summaries  \\\n",
       "0  Since the beginning of the HIV epidemic, nurse...   \n",
       "1  Afghanistan is in the early stage of dramatic ...   \n",
       "2  Afghanistan is increasingly facing an HIV epid...   \n",
       "3  According to BBC reports, Mohammad Ali, who is...   \n",
       "4  KABUL - Officials of the Ministry of Public He...   \n",
       "\n",
       "                                         Source_URLs  \n",
       "0  http://www.outlookafghanistan.net/topics.php?p...  \n",
       "1  http://outlookafghanistan.net/topics.php?post_...  \n",
       "2  http://outlookafghanistan.net/topics.php?post_...  \n",
       "3  http://outlookafghanistan.net/topics.php?post_...  \n",
       "4  http://outlookafghanistan.net/national_detail....  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(headlines) == len(descriptions) == len(authors) == len(dates) == len(news) == len(publication) == len(keywords) == len(summaries) == len(urls) == len(category):\n",
    "    tbl = pd.DataFrame({'Headlines' : headlines,\n",
    "                        'Descriptions' : descriptions,\n",
    "                        'Authors' : authors,\n",
    "                        'Published_Dates' : dates,\n",
    "                        'Publication' : publication,\n",
    "                        'Articles' : news,\n",
    "                        'category' : category,\n",
    "                        'Keywords' : keywords,\n",
    "                        'Summaries' : summaries,\n",
    "                        'Source_URLs' : urls})\n",
    "    tbl.dropna()\n",
    "    path = 'D:\\\\#Backups\\\\Desktop\\\\!Code!\\\\CDRI\\\\HIV\\\\Data Extraction\\\\#Datasets\\\\'\n",
    "    tbl.to_csv(path+'Daily_Outlook_Afghanistan.csv', index=False)\n",
    "else:\n",
    "    print('Array lenght does not match!')\n",
    "\n",
    "tbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
