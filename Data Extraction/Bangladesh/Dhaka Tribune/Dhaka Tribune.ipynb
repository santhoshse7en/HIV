{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIV News articles extraction from Dhaka Tribune. Data Extraction of following parameters\n",
    "- Headline\n",
    "- Description\n",
    "- Author\n",
    "- Published_Date\n",
    "- News\n",
    "- URL\n",
    "- Keywords\n",
    "- Summary\n",
    "\n",
    "### Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options # enables options in web browser\n",
    "from selenium import webdriver # web-based automation tool for Python\n",
    "from newspaper import Article # Article scraping & curation\n",
    "from bs4 import BeautifulSoup # Python library for pulling data out of HTML and XML files\n",
    "from requests import get # standard for making HTTP requests in Python\n",
    "import pandas as pd # library written for data manipulation and analysis\n",
    "import sys, time #  System-specific parameters and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Empty lists for HIV News Articles parameters data to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines, descriptions, dates, authors, news, keywords, summaries, urls = [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the total no.of.pages by total no.of articles from google search results¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'HIV site:www.dhakatribune.com'\n",
    "\n",
    "url = 'https://www.google.com/search?q=' + '+'.join(keyword.split())\n",
    "\n",
    "soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "try:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 680 results (0.23 seconds)\n",
    "    max_pages = round([int(s) for s in soup.select_one('div#resultStats').text.split() if s.isdigit()][0]/10)\n",
    "    max_pages = max_pages + 1\n",
    "except:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 1,080 results (0.23 seconds)\n",
    "    max_pages = round(int(''.join(i for i in soup.select_one('div#resultStats').text if i.isdigit()))/10)\n",
    "    max_pages = max_pages + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates max_pages value through while loop. Scraping the Articles urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 : 68\r"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome(options=options)\n",
    "browser.get(url)\n",
    "\n",
    "index = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        index +=1\n",
    "        page = browser.page_source\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        linky = [soup.select('.r')[i].a['href'] for i in range(len(soup.select('.r')))]\n",
    "        urls.extend(linky)\n",
    "        if index == max_pages:\n",
    "            break\n",
    "        browser.find_element_by_xpath('//*[@id=\"pnnext\"]/span[2]').click()\n",
    "        time.sleep(2)\n",
    "        sys.stdout.write('\\r' + str(index) + ' : ' + str(max_pages) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To remove duplicates urls entries in the list by executing below line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "urls = list(dict.fromkeys(urls))\n",
    "print(len(urls), type(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates urls through for loop. Scraping the Articles with above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 53sakatribune.com/feature/health-wellness/2017/09/22/sanofi-tests-three-one-antibody-treat-prevent-hiv/attachment/bigstock-196161664/1647834805237587830307623093_1953323341359665\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, url in enumerate(urls):\n",
    "    try:\n",
    "        # Parse the url to NewsPlease \n",
    "        soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        \n",
    "        # Extracts the Headlines\n",
    "        try:\n",
    "            try:\n",
    "                headlines.append(article.title.strip())\n",
    "            except:\n",
    "                headlines.append(soup.select_one('meta[property=\"title\"]')['content'].strip())\n",
    "        except:\n",
    "            headlines.append(None)\n",
    "            \n",
    "        # Extracts the Descriptions    \n",
    "        try:\n",
    "            try:\n",
    "                descriptions.append(article.meta_description.strip().replace(u'\\xa0', u' ').replace('\\r\\n        \\t \\r\\n        \\r\\n        \\t',''))\n",
    "            except:\n",
    "                descriptions.append(soup.select_one('meta[name=\"description\"]')['content'].replace('\\r\\n        \\t&nbsp;\\r\\n        \\r\\n        \\t', ''))\n",
    "        except:\n",
    "            descriptions.append(None)\n",
    "            \n",
    "        # Extracts the Authors\n",
    "        try:\n",
    "            try:\n",
    "                authors.append(article.authors.strip())\n",
    "            except:\n",
    "                authors.append(soup.select_one('.ptt.author-bg').a.text.strip())\n",
    "        except:\n",
    "            authors.append(None)\n",
    "        \n",
    "        # Extracts the published dates\n",
    "        try:\n",
    "            try:\n",
    "                dates.append(str(article.publish_date))\n",
    "            except:\n",
    "                dates.append(soup.select_one('meta[property=\"article:published_time\"]')['content'].strip())\n",
    "        except:\n",
    "            dates.append(None)\n",
    "            \n",
    "        # Extracts the news articles\n",
    "        try:\n",
    "            try:\n",
    "                news.append(article.text.strip())\n",
    "            except:\n",
    "                news.append(soup.select_one('div.report-content.fr-view').text.replace('\\n', '').strip())\n",
    "        except:\n",
    "            news.append(None)\n",
    "            \n",
    "        # Extracts Keywords and Summaries    \n",
    "        try:\n",
    "            keywords.append(article.keywords)\n",
    "            summaries.append(article.summary)\n",
    "        except:\n",
    "            keywords.append(None)\n",
    "            summaries.append(None)\n",
    "            \n",
    "    except:\n",
    "        headlines.append(None)\n",
    "        descriptions.append(None)\n",
    "        authors.append(None)\n",
    "        dates.append(None)\n",
    "        news.append(None)\n",
    "        keywords.append(None)\n",
    "        summaries.append(None)\n",
    "\n",
    "    sys.stdout.write('\\r' + str(index) + ' : ' + str(url) + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Array Length of each list to create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 242 242 242 242 242 242 242\n"
     ]
    }
   ],
   "source": [
    "print(len(headlines), len(descriptions), len(authors), len(dates), len(news), len(keywords), len(summaries), len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a csv file after checking array length and droping the missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_Dates</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Report: 193 tested HIV-positive in 8 southern ...</td>\n",
       "      <td>The report highlights that returning expatriat...</td>\n",
       "      <td>Tribune Desk</td>\n",
       "      <td>2018-09-30 00:00:00</td>\n",
       "      <td>Representational photo Bigstock\\n\\nThe report ...</td>\n",
       "      <td>[report, hiv, 193, spreading, organization, kh...</td>\n",
       "      <td>Representational photo BigstockThe report high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HIV deaths: Bangladesh ranks 10th in Asia, Ind...</td>\n",
       "      <td>There are currently around 12,000 HIV-positive...</td>\n",
       "      <td>Tribune Desk</td>\n",
       "      <td>2018-01-26 00:00:00</td>\n",
       "      <td>Bangladesh recorded the 10th highest number of...</td>\n",
       "      <td>[south, hiv, data, asia, ranks, asian, banglad...</td>\n",
       "      <td>Bangladesh recorded the 10th highest number of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World AIDS Day observed: Tuberculosis patients...</td>\n",
       "      <td>The World Aids Day was observed yesterday acro...</td>\n",
       "      <td>Hedait Hossain Molla, Khulna</td>\n",
       "      <td>2016-12-02 00:00:00</td>\n",
       "      <td>This year’s slogan for the day is “Let’s raise...</td>\n",
       "      <td>[day, hiv, total, bangladesh, prevalence, viru...</td>\n",
       "      <td>According to the Mukta Akash Bangladesh, a non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fight HIV, not sex workers</td>\n",
       "      <td>We need to address the social problems that ma...</td>\n",
       "      <td>Md Abdul Quayyum</td>\n",
       "      <td>2016-12-18 00:00:00</td>\n",
       "      <td>“My father died in a road accident when I was ...</td>\n",
       "      <td>[health, hiv, sex, fight, violence, bangladesh...</td>\n",
       "      <td>But sex workers are among those who are most v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Latest news update from HIV in Bangladesh, World</td>\n",
       "      <td>Latest HIV news in Bangladesh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9-year-old South African becomes third...\\n\\nA...</td>\n",
       "      <td>[south, hiv, taken, old, given, bangladesh, th...</td>\n",
       "      <td>9-year-old South African becomes third...Afric...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines  \\\n",
       "0  Report: 193 tested HIV-positive in 8 southern ...   \n",
       "1  HIV deaths: Bangladesh ranks 10th in Asia, Ind...   \n",
       "2  World AIDS Day observed: Tuberculosis patients...   \n",
       "3                         Fight HIV, not sex workers   \n",
       "4   Latest news update from HIV in Bangladesh, World   \n",
       "\n",
       "                                        Descriptions  \\\n",
       "0  The report highlights that returning expatriat...   \n",
       "1  There are currently around 12,000 HIV-positive...   \n",
       "2  The World Aids Day was observed yesterday acro...   \n",
       "3  We need to address the social problems that ma...   \n",
       "4                      Latest HIV news in Bangladesh   \n",
       "\n",
       "                        Authors      Published_Dates  \\\n",
       "0                  Tribune Desk  2018-09-30 00:00:00   \n",
       "1                  Tribune Desk  2018-01-26 00:00:00   \n",
       "2  Hedait Hossain Molla, Khulna  2016-12-02 00:00:00   \n",
       "3              Md Abdul Quayyum  2016-12-18 00:00:00   \n",
       "4                          None                 None   \n",
       "\n",
       "                                            Articles  \\\n",
       "0  Representational photo Bigstock\\n\\nThe report ...   \n",
       "1  Bangladesh recorded the 10th highest number of...   \n",
       "2  This year’s slogan for the day is “Let’s raise...   \n",
       "3  “My father died in a road accident when I was ...   \n",
       "4  9-year-old South African becomes third...\\n\\nA...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [report, hiv, 193, spreading, organization, kh...   \n",
       "1  [south, hiv, data, asia, ranks, asian, banglad...   \n",
       "2  [day, hiv, total, bangladesh, prevalence, viru...   \n",
       "3  [health, hiv, sex, fight, violence, bangladesh...   \n",
       "4  [south, hiv, taken, old, given, bangladesh, th...   \n",
       "\n",
       "                                           Summaries  \n",
       "0  Representational photo BigstockThe report high...  \n",
       "1  Bangladesh recorded the 10th highest number of...  \n",
       "2  According to the Mukta Akash Bangladesh, a non...  \n",
       "3  But sex workers are among those who are most v...  \n",
       "4  9-year-old South African becomes third...Afric...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = pd.DataFrame({'Headlines' : headlines,\n",
    "                    'Descriptions' : descriptions,\n",
    "                    'Authors' : authors,\n",
    "                    'Published_Dates' : dates, \n",
    "                    'Articles' : news,\n",
    "                    'Keywords' : keywords,\n",
    "                    'Summaries' : summaries,})\n",
    "#tbl = tbl.dropna()\n",
    "tbl.to_csv('Dhaka_Tribune.csv', index=False)\n",
    "tbl.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
