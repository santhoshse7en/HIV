{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIV News articles extraction from The Jakarta Post. Data Extraction of following parameters\n",
    "- Headline\n",
    "- Description\n",
    "- Author\n",
    "- Published Date\n",
    "- Category\n",
    "- Publication\n",
    "- News\n",
    "- URL\n",
    "- Keywords\n",
    "- Summary\n",
    "\n",
    "### Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options # enables options in web browser\n",
    "from selenium import webdriver # web-based automation tool for Python\n",
    "from newspaper import Article # Article scraping & curation\n",
    "from bs4 import BeautifulSoup # Python library for pulling data out of HTML and XML files\n",
    "from requests import get # standard for making HTTP requests in Python\n",
    "import pandas as pd # library written for data manipulation and analysis\n",
    "import sys, time #  System-specific parameters and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Empty lists for HIV News Articles parameters data to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines, descriptions, dates, authors, news, keywords, summaries, urls, category, publication = [], [], [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the total no.of.pages by total no.of articles from google search resultsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'HIV site:www.thejakartapost.com'\n",
    "\n",
    "url = 'https://www.google.com/search?q=' + '+'.join(keyword.split())\n",
    "\n",
    "soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "try:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 680 results (0.23 seconds)\n",
    "    max_pages = round([int(s) for s in soup.select_one('div#resultStats').text.split() if s.isdigit()][0]/10)\n",
    "    max_pages = max_pages + 1\n",
    "except:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 1,080 results (0.23 seconds)\n",
    "    max_pages = round(int(''.join(i for i in soup.select_one('div#resultStats').text if i.isdigit()))/10)\n",
    "    max_pages = max_pages + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates max_pages value through while loop. Scraping the Articles urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 : 222\r"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome(options=options)\n",
    "browser.get(url)\n",
    "\n",
    "index = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        index +=1\n",
    "        page = browser.page_source\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        linky = [soup.select('.r')[i].a['href'] for i in range(len(soup.select('.r')))]\n",
    "        urls.extend(linky)\n",
    "        if index == max_pages:\n",
    "            break\n",
    "        browser.find_element_by_xpath('//*[@id=\"pnnext\"]/span[2]').click()\n",
    "        time.sleep(2)\n",
    "        sys.stdout.write('\\r' + str(index) + ' : ' + str(max_pages) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To remove duplicates urls entries in the list by executing below line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Extracted URL's are : 156 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "urls = list(dict.fromkeys(urls))\n",
    "print(\"Total Extracted URL's are\" + ' : ' + str(len(urls)), type(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates urls through for loop. Scraping the Articles with above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 24shejakartapost.com/news/2012/03/03/number-people-with-hivaids-increasing-c-java.htmllap.html-deputy-minister.html61341112\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, url in enumerate(urls):\n",
    "    try:\n",
    "        # Parse the url to NewsPlease\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        \n",
    "        # Extracts the Headlines\n",
    "        try:\n",
    "            headlines.append(article.title.strip())\n",
    "        except:\n",
    "            headlines.append(None)\n",
    "            \n",
    "        # Extracts the Descriptions    \n",
    "        try:\n",
    "            descriptions.append(' '.join(article.meta_data['og']['description'].split()))\n",
    "        except:\n",
    "            descriptions.append(None)\n",
    "            \n",
    "        # Extracts the Authors\n",
    "        try:\n",
    "            authors.append(article.authors)\n",
    "        except:\n",
    "            authors.append(None)\n",
    "        \n",
    "        # Extracts the published dates\n",
    "        try:\n",
    "            dates.append(str(article.publish_date).split()[0])\n",
    "        except:\n",
    "            dates.append(None)\n",
    "            \n",
    "        # Extracts the news category\n",
    "        try:\n",
    "            category.append(article.meta_data['category'])\n",
    "        except:\n",
    "            category.append(None)\n",
    "            \n",
    "        # Extracts the news articles\n",
    "        try:\n",
    "            news.append(' '.join(article.text.split()).replace(\"\\'\\'\",\" \").replace(\"\\'\", \"\").replace(\" / \", \"\"))\n",
    "        except:\n",
    "            news.append(None)\n",
    "            \n",
    "        # Extracts the news publication\n",
    "        try:\n",
    "            publication.append(article.meta_data['og']['site_name'])\n",
    "        except:\n",
    "            publication.append(None)\n",
    "\n",
    "        # Extracts Keywords and Summaries\n",
    "        try:\n",
    "            keywords.append(article.keywords)\n",
    "            summaries.append(' '.join(article.summary.split()))\n",
    "        except:\n",
    "            keywords.append(None)\n",
    "            summaries.append(None)\n",
    "                        \n",
    "    except:\n",
    "        headlines.append(None)\n",
    "        descriptions.append(None)\n",
    "        authors.append(None)\n",
    "        dates.append(None)\n",
    "        category.append(None)\n",
    "        publication.append(None)\n",
    "        news.append(None)\n",
    "        keywords.append(None)\n",
    "        summaries.append(None)\n",
    "\n",
    "    sys.stdout.write('\\r' + str(index) + ' : ' + str(url) + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Array Length of each list to create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 156 156 156 156 156 156 156 156 156\n"
     ]
    }
   ],
   "source": [
    "print(len(headlines), len(descriptions), len(authors), len(dates), len(category), len(publication), len(news), len(keywords), len(summaries), len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a csv file after checking array length and droping the missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_Dates</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Articles</th>\n",
       "      <th>category</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Summaries</th>\n",
       "      <th>Source_URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Curious about HIV/AIDS? Just Ask Marlo</td>\n",
       "      <td>A new online chat platform is the latest innov...</td>\n",
       "      <td>[The Jakarta Post]</td>\n",
       "      <td>2019-01-22</td>\n",
       "      <td>The Jakarta Post</td>\n",
       "      <td>A new online chat platform is the latest innov...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[curious, users, hivaids, marlo, test, hiv, tr...</td>\n",
       "      <td>The platform called Tanya Marlo (Ask Marlo) fe...</td>\n",
       "      <td>https://www.thejakartapost.com/life/2019/01/22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discrimination against children with HIV/AIDS ...</td>\n",
       "      <td>Regional health agencies only handle HIV/AIDS ...</td>\n",
       "      <td>[The Jakarta Post]</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>The Jakarta Post</td>\n",
       "      <td>The Indonesia AIDS Coalition (IAC) has urged t...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[infected, parents, hivaids, evidence, discrim...</td>\n",
       "      <td>âThe President should establish a special cros...</td>\n",
       "      <td>https://www.thejakartapost.com/news/2019/02/19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HIV patient's remission spurs hope for curing ...</td>\n",
       "      <td>A stem-cell treatment put a London patientâs H...</td>\n",
       "      <td>[The Jakarta Post]</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>The Jakarta Post</td>\n",
       "      <td>A stem-cell treatment put a London patientâs H...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[virus, stem, aidscausing, hiv, patients, mill...</td>\n",
       "      <td>Hematopoietic stem cells give rise to other bl...</td>\n",
       "      <td>https://www.thejakartapost.com/life/2019/03/05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'We had no choice': Surakarta school expels st...</td>\n",
       "      <td>Purwotomo 74 public elementary school in Surak...</td>\n",
       "      <td>[The Jakarta Post]</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>The Jakarta Post</td>\n",
       "      <td>Purwotomo 74 public elementary school in Surak...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[parents, surakarta, hivaids, choice, protests...</td>\n",
       "      <td>Purwotomo 74 public elementary school in Surak...</td>\n",
       "      <td>https://www.thejakartapost.com/news/2019/02/08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data of 14,200 HIV positive people leaked in S...</td>\n",
       "      <td>An American convicted of numerous crimes is be...</td>\n",
       "      <td>[The Jakarta Post]</td>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>The Jakarta Post</td>\n",
       "      <td>Confidential data of 14,200 people diagnosed w...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[14200, data, positive, leaked, singapore, hiv...</td>\n",
       "      <td>Confidential data of 14,200 people diagnosed w...</td>\n",
       "      <td>https://www.thejakartapost.com/seasia/2019/01/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines  \\\n",
       "0             Curious about HIV/AIDS? Just Ask Marlo   \n",
       "1  Discrimination against children with HIV/AIDS ...   \n",
       "2  HIV patient's remission spurs hope for curing ...   \n",
       "3  'We had no choice': Surakarta school expels st...   \n",
       "4  Data of 14,200 HIV positive people leaked in S...   \n",
       "\n",
       "                                        Descriptions             Authors  \\\n",
       "0  A new online chat platform is the latest innov...  [The Jakarta Post]   \n",
       "1  Regional health agencies only handle HIV/AIDS ...  [The Jakarta Post]   \n",
       "2  A stem-cell treatment put a London patientâs H...  [The Jakarta Post]   \n",
       "3  Purwotomo 74 public elementary school in Surak...  [The Jakarta Post]   \n",
       "4  An American convicted of numerous crimes is be...  [The Jakarta Post]   \n",
       "\n",
       "  Published_Dates       Publication  \\\n",
       "0      2019-01-22  The Jakarta Post   \n",
       "1      2019-02-19  The Jakarta Post   \n",
       "2      2019-03-05  The Jakarta Post   \n",
       "3      2019-02-08  The Jakarta Post   \n",
       "4      2019-01-29  The Jakarta Post   \n",
       "\n",
       "                                            Articles category  \\\n",
       "0  A new online chat platform is the latest innov...       {}   \n",
       "1  The Indonesia AIDS Coalition (IAC) has urged t...       {}   \n",
       "2  A stem-cell treatment put a London patientâs H...       {}   \n",
       "3  Purwotomo 74 public elementary school in Surak...       {}   \n",
       "4  Confidential data of 14,200 people diagnosed w...       {}   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [curious, users, hivaids, marlo, test, hiv, tr...   \n",
       "1  [infected, parents, hivaids, evidence, discrim...   \n",
       "2  [virus, stem, aidscausing, hiv, patients, mill...   \n",
       "3  [parents, surakarta, hivaids, choice, protests...   \n",
       "4  [14200, data, positive, leaked, singapore, hiv...   \n",
       "\n",
       "                                           Summaries  \\\n",
       "0  The platform called Tanya Marlo (Ask Marlo) fe...   \n",
       "1  âThe President should establish a special cros...   \n",
       "2  Hematopoietic stem cells give rise to other bl...   \n",
       "3  Purwotomo 74 public elementary school in Surak...   \n",
       "4  Confidential data of 14,200 people diagnosed w...   \n",
       "\n",
       "                                         Source_URLs  \n",
       "0  https://www.thejakartapost.com/life/2019/01/22...  \n",
       "1  https://www.thejakartapost.com/news/2019/02/19...  \n",
       "2  https://www.thejakartapost.com/life/2019/03/05...  \n",
       "3  https://www.thejakartapost.com/news/2019/02/08...  \n",
       "4  https://www.thejakartapost.com/seasia/2019/01/...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(headlines) == len(descriptions) == len(authors) == len(dates) == len(news) == len(publication) == len(keywords) == len(summaries) == len(urls) == len(category):\n",
    "    tbl = pd.DataFrame({'Headlines' : headlines,\n",
    "                        'Descriptions' : descriptions,\n",
    "                        'Authors' : authors,\n",
    "                        'Published_Dates' : dates,\n",
    "                        'Publication' : publication,\n",
    "                        'Articles' : news,\n",
    "                        'category' : category,\n",
    "                        'Keywords' : keywords,\n",
    "                        'Summaries' : summaries,\n",
    "                        'Source_URLs' : urls})\n",
    "    tbl.dropna()\n",
    "    path = 'D:\\\\#Backups\\\\Desktop\\\\!Code!\\\\CDRI\\\\HIV\\\\Data Extraction\\\\#Datasets\\\\'\n",
    "    tbl.to_csv(path+'The Jakarta Post.csv', index=False)\n",
    "else:\n",
    "    print('Array lenght does not match!')\n",
    "    \n",
    "tbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
